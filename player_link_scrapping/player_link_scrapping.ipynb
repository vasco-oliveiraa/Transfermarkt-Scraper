{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000da14-7153-4ec1-a90f-68508908f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2998ed-f0e8-4a27-84eb-9dcd74063958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary headers to store the User-Agent string for the request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0;Win64) AppleWebkit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}\n",
    "\n",
    "# Store a list of URLs for 10 top football teams\n",
    "teams = [\n",
    "    'https://www.transfermarkt.com/real-madrid/startseite/verein/418',\n",
    "    'https://www.transfermarkt.com/fc-bayern-munchen/startseite/verein/27',\n",
    "    'https://www.transfermarkt.com/fc-barcelona/startseite/verein/131',\n",
    "    'https://www.transfermarkt.com/manchester-united/startseite/verein/985',\n",
    "    'https://www.transfermarkt.com/juventus-turin/startseite/verein/506',\n",
    "    'https://www.transfermarkt.com/fc-chelsea/startseite/verein/631',\n",
    "    'https://www.transfermarkt.com/fc-liverpool/startseite/verein/31',\n",
    "    'https://www.transfermarkt.com/manchester-city/startseite/verein/281',\n",
    "    'https://www.transfermarkt.com/fc-paris-saint-germain/startseite/verein/583',\n",
    "    'https://www.transfermarkt.com/atletico-madrid/startseite/verein/13'\n",
    "]\n",
    "\n",
    "# Store a range of years from 2012 to 2022\n",
    "years = range(2012,2022)\n",
    "\n",
    "# Initialize an empty list to store player links\n",
    "players = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62e90f-a166-45ae-9c37-f028d15ca7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through the teams list\n",
    "for team in teams:\n",
    "    # Loop through the years list\n",
    "    for n in years:\n",
    "        # Concatenate the team name and year to create the URL\n",
    "        team_url_season = str(team) + '?saison_id='+ str(n)\n",
    "        \n",
    "        # Use a while loop to ensure the code runs until the data is extracted\n",
    "        while True:\n",
    "            try:\n",
    "                # Make a GET request to the URL and parse the HTML\n",
    "                request = rq.get(team_url_season, headers=headers)\n",
    "                soup = bs(request.text, 'html.parser')\n",
    "                # Find the first table with class \"items\" and store it in players_table\n",
    "                players_table = soup.find_all('table', class_='items')[0]\n",
    "                # Find all links within the players_table and store them in links\n",
    "                links = players_table.find_all('a')\n",
    "                # Extract the href attribute from the links and store it in links\n",
    "                links = [l.get(\"href\") for l in links]\n",
    "                # Filter the links list to include only player profiles\n",
    "                links = [l for l in links if '/profil/spieler/' in l]\n",
    "                # Add the extracted player links to the players list\n",
    "                players.extend(links)\n",
    "                # Break the loop since the data has been extracted\n",
    "                break\n",
    "            except IndexError:\n",
    "                # Print a message and sleep for 10 seconds if an IndexError occurs\n",
    "                print('Index Error : Sleeping for 10 seconds before retrying')\n",
    "                sleep(10)\n",
    "        # Print the team name and year after data extraction is complete\n",
    "        print(team.split('/')[3], n)\n",
    "        # Sleep for a random time between 1 and 3 seconds to avoid rate-limiting\n",
    "        sleep(randint(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57979a-b834-4220-9175-92cce836bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the key 'URL' and values 'players'\n",
    "dict_players = {'URL' : players}\n",
    "\n",
    "# Convert the dictionary to a pandas dataframe 'df'\n",
    "df = pd.DataFrame(dict_players)\n",
    "\n",
    "# Remove duplicates in the 'URL' column\n",
    "df = df.drop_duplicates(subset = 'URL')\n",
    "\n",
    "# Reset the index of the dataframe to start from 0\n",
    "df.index = range(0,len(df))\n",
    "\n",
    "# Prefix the 'URL' column with 'https://www.transfermarkt.com'\n",
    "df['URL'] = 'https://www.transfermarkt.com' + df['URL'].astype(str)\n",
    "\n",
    "# Write the dataframe to a csv file at 'output/player_links.csv'\n",
    "df.to_csv('output/player_links.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
