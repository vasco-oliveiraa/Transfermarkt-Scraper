{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "833c881f-0075-4fc1-81d2-fa98a2c9ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80849bbf-f62c-4321-bad5-a567f97ad152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the player links from the csv file\n",
    "df_links = pd.read_csv('../player_link_scrapping/output/player_links.csv')\n",
    "\n",
    "# Convert the 'URL' column of the dataframe to a list\n",
    "links = df_links['URL'].tolist()\n",
    "\n",
    "# Define a dictionary headers to store the User-Agent string for the request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0;Win64) AppleWebkit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696eea1f-25c3-4b25-8c43-2cbf84e0b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store data of each player in the form of a dictionary\n",
    "list_of_row_dicts = []\n",
    "\n",
    "# Loop through each link to scrape player data\n",
    "for link in links:\n",
    "\n",
    "    # Keep trying until the request is successful\n",
    "    while True:\n",
    "        try:\n",
    "            # Make a GET request to the link\n",
    "            request = rq.get(link,headers=headers)\n",
    "        \n",
    "            # Use BeautifulSoup to parse the HTML content of the page\n",
    "            soup = bs(request.text, 'html.parser')\n",
    "            \n",
    "            # Find all <span> tags in the HTML\n",
    "            title_spans = soup.find_all('span')\n",
    "            \n",
    "            # Break out of the loop if the request is successful\n",
    "            break\n",
    "        except AttributeError:\n",
    "            # Print error message and wait for 10 seconds before retrying\n",
    "            print('Index Error : Sleeping for 10 seconds before retrying')\n",
    "            sleep(10)\n",
    "            \n",
    "    try:\n",
    "        name = ' '.join([word for word in soup.find('h1').text.split() if not any(i.isdigit() for i in word)])\n",
    "    except IndexError:\n",
    "        name = None\n",
    "        print ('Name not found')\n",
    "\n",
    "    try:\n",
    "        date_of_birth = [span.find_next('span').text for span in title_spans if 'Date of birth:' in span.text][0].strip()\n",
    "    except IndexError:\n",
    "        date_of_birth = None\n",
    "        print ('DOB not found')\n",
    "\n",
    "    try:\n",
    "        city_of_birth = [span.find_next('span').text.strip() for span in title_spans if 'Place of birth:' in span.text][0]\n",
    "    except IndexError:\n",
    "        city_of_birth = None\n",
    "        print ('City not found')\n",
    "\n",
    "    try:\n",
    "        country_of_birth = [span.find_next('span').find('img')['title'].strip() for span in title_spans if 'Place of birth:' in span.text][0]\n",
    "    except IndexError:\n",
    "        country_of_birth = None\n",
    "        print ('Country not found')\n",
    "\n",
    "    try:\n",
    "        citizenship = [span.find_next('span').text.strip().split('\\xa0\\xa0') for span in title_spans if 'Citizenship:' in span.text][0]\n",
    "    except AttributeError:\n",
    "        citizenship = None\n",
    "        print ('Citizenship not found')\n",
    "\n",
    "    try:\n",
    "        height = [span.find_next('span').text for span in title_spans if 'Height:' in span.text][0].split()[0]\n",
    "    except IndexError:\n",
    "        height = None\n",
    "        print ('Height not found')\n",
    "\n",
    "    try:\n",
    "        foot = [span.find_next('span').text for span in title_spans if 'Foot:' in span.text][0]\n",
    "    except IndexError:\n",
    "        foot = None\n",
    "        print ('Foot not found')\n",
    "\n",
    "    try:\n",
    "        agent = [span.find_next('span').text for span in title_spans if 'Player agent:' in span.text][0].strip()\n",
    "    except IndexError:\n",
    "        agent = None\n",
    "        print ('Agent not found')\n",
    "\n",
    "    try:\n",
    "        outfitter = [span.find_next('span').text for span in title_spans if 'Outfitter:' in span.text][0]\n",
    "    except IndexError:\n",
    "        outfitter = None\n",
    "        print ('Outfitter not found')\n",
    "\n",
    "    try:\n",
    "        main_position = soup.find('dt', text='Main position:').find_next('dd').text\n",
    "    except AttributeError:\n",
    "        main_position = None\n",
    "        print ('Main Position not found')\n",
    "\n",
    "    try:\n",
    "        other_position = [dt.text for dt in soup.find('dt', text='Other position:').find_next_siblings('dd')]\n",
    "    except AttributeError:\n",
    "        other_position = None\n",
    "        print ('Other Postion not found')\n",
    "\n",
    "    try:\n",
    "        youth_club = soup.find('div', class_='box tm-player-additional-data viewport-tracking').find('div', class_='content').text.strip().split(',')\n",
    "    except AttributeError:\n",
    "        youth_club = None\n",
    "        print ('Youth Club not found')\n",
    "            \n",
    "    row_dic = {\n",
    "    'Player_URL' : link,\n",
    "    'Name' : name,\n",
    "    'Date_of_Birth': date_of_birth,\n",
    "    'City_of_Birth' : city_of_birth,\n",
    "    'Country_of_Birth' : country_of_birth,\n",
    "    'Citizenship' : citizenship,\n",
    "    'Height' : height,\n",
    "    'Foot' : foot,\n",
    "    'Agent' : agent,\n",
    "    'Outfitter' : outfitter,\n",
    "    'Main_Position' : main_position,\n",
    "    'Other_Position' : other_position,\n",
    "    'Youth_Club' : youth_club\n",
    "    }\n",
    "    list_of_row_dicts.append(row_dic)\n",
    "            \n",
    "    print(name)\n",
    "    sleep(randint(1,3))\n",
    "\n",
    "df = pd.DataFrame(list_of_row_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e3a0690-28df-48d1-99b4-e55ca75d1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/player_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
